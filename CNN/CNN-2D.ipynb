{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652af7e-f4c1-46f5-9983-e9f073df1749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10590cda-fead-46cb-9e5c-48177587e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have access to moduels\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.realpath('')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f07af-82db-4f43-b7ae-17f0e5ae8793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from torchvision.transforms import Compose, GaussianBlur, RandomRotation, RandomChoice, RandomApply, RandomAffine, Resize\n",
    "from dataloader.transforms import GaussianNoise\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from colorama import Fore\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dataloader.dataset import ADNI3Channels\n",
    "from dataloader.dataloader import ADNILoader\n",
    "\n",
    "from utils.utils import count_parameters, save_model\n",
    "from utils.report import cnn_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd845d-a646-403e-8b16-5999df57f767",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0aa7a-2ace-460d-bdfd-a470e24cc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (384, 384)\n",
    "resize = Resize(size=image_size)\n",
    "gaussian_blur = GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2))\n",
    "gaussian_noise = GaussianNoise(mean=0, std=0.001)\n",
    "random_rotation = RandomRotation(degrees=3)\n",
    "random_translate = RandomAffine(degrees=0, translate=(0.01, 0.01))\n",
    "random_choice = RandomChoice([random_rotation, random_translate])\n",
    "random_transforms = RandomApply([random_choice], p=0.2)\n",
    "\n",
    "train_transforms = Compose([resize, random_transforms])\n",
    "valid_transforms = Compose([resize])\n",
    "test_transforms = Compose([resize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d16e77-75f9-4675-a538-767aee133120",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ADNI3Channels(\"../Data/Training/\", transforms=train_transforms)\n",
    "valid_ds = ADNI3Channels(\"../Data/Validation/\", transforms=valid_transforms)\n",
    "test_ds = ADNI3Channels(\"../Data/Test/\", transforms=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053da8b9-7744-4552-9db5-c93ad3307c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "image, label = train_ds[idx]\n",
    "\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label:\", label.item())\n",
    "\n",
    "print(\"Number of training samples:\", len(train_ds))\n",
    "print(\"Number of validation samples:\", len(valid_ds))\n",
    "print(\"Number of test samples:\", len(test_ds), \"\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(6, 2), dpi=300)\n",
    "for i in range(3):\n",
    "    axes[i].imshow(image[i, :, :])\n",
    "    axes[i].axis(\"off\");\n",
    "    # print(image[i, :, :].min(), image[i, :, :].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75590ba-ad21-496b-9a08-f6992fd77369",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"CN\", 1: \"MCI\", 2: \"AD\"}\n",
    "label2id = {\"CN\": 0, \"MCI\": 1, \"AD\": 2}\n",
    "\n",
    "print(id2label[label.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9beb7-69d8-4fdc-84e0-fb3bc1bfb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 5\n",
    "valid_batch_size = 2\n",
    "test_batch_size = 2\n",
    "\n",
    "hparams = {'train_ds': train_ds,\n",
    "           'valid_ds': valid_ds,\n",
    "           'test_ds': test_ds,\n",
    "           'train_batch_size': train_batch_size,\n",
    "           'valid_batch_size': valid_batch_size,\n",
    "           'test_batch_size': test_batch_size,\n",
    "           'num_workers': 20\n",
    "          }\n",
    "\n",
    "train_dataloader = ADNILoader(**hparams).train_dataloader()\n",
    "valid_dataloader= ADNILoader(**hparams).validation_dataloader()\n",
    "test_dataloader = ADNILoader(**hparams).test_dataloader()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch[0].shape)\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f30a4-a8e6-425b-837d-135bdd21c37f",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38762a83-6483-4b66-ac5b-0ebd1f387dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_labels=3):\n",
    "        super(CNN, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3)),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3)),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.MaxPool2d(kernel_size=(3, 3)),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3)),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.MaxPool2d(kernel_size=(3, 3)),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(204800, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 3),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e6a47-59fb-43b4-8a2b-b8b282f63d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "model = CNN(3).to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "class_0_freq = 140\n",
    "class_1_freq = 160\n",
    "class_2_freq = 160\n",
    "weight = torch.tensor([1/class_0_freq, 1/class_1_freq, 1/class_2_freq]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight)\n",
    "\n",
    "accuracy = Accuracy(num_classes=3)\n",
    "writer = SummaryWriter()\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac362c14-f0b2-4b21-9ab1-aaccf416d3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "best_loss = 100\n",
    "best_acc = 0\n",
    "saved = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(Fore.YELLOW + f\"Epoch: {(epoch+1):02}/{epochs}\")\n",
    "    for step, (x, y) in enumerate(train_dataloader):\n",
    "        x, y  = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        preds = logits.argmax(1)\n",
    "        acc = accuracy(y.cpu(), preds.cpu())\n",
    "        optimizer.zero_grad()           \n",
    "        loss.backward()                 \n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "        train_accs.append(acc.item())\n",
    "    \n",
    "        if (step % 20 == 0) or (step == len(train_dataloader)):\n",
    "            train_loss = sum(train_losses)/len(train_losses)\n",
    "            train_acc = sum(train_accs)/len(train_accs)\n",
    "            writer.add_scalar('train_loss', train_loss, epoch * len(train_dataloader) + step)\n",
    "            writer.add_scalar('train_acc', train_acc, epoch * len(train_dataloader) + step)\n",
    "            train_losses.clear()\n",
    "            train_accs.clear()\n",
    "            \n",
    "            model.eval() \n",
    "            with torch.no_grad():\n",
    "                for x, y in valid_dataloader:\n",
    "                    x, y  = x.to(device), y.to(device)\n",
    "                    logits = model(x)\n",
    "                    loss = criterion(logits, y)\n",
    "                    preds = logits.argmax(1)\n",
    "                    acc = accuracy(y.cpu(), preds.cpu())\n",
    "                    valid_losses.append(loss.item())\n",
    "                    valid_accs.append(acc.item())\n",
    "            \n",
    "            valid_loss = sum(valid_losses)/len(valid_losses)\n",
    "            valid_acc = sum(valid_accs)/len(valid_accs)\n",
    "            writer.add_scalar('valid_loss', valid_loss, epoch * len(train_dataloader) + step)\n",
    "            writer.add_scalar('valid_acc', valid_acc, epoch * len(train_dataloader) + step)\n",
    "            valid_losses.clear()\n",
    "            valid_accs.clear()\n",
    "            \n",
    "            if best_loss > valid_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model_loss = deepcopy(model.state_dict())\n",
    "                saved = True\n",
    "                \n",
    "            if best_acc < valid_acc:\n",
    "                best_acc = valid_acc\n",
    "                best_model_acc = deepcopy(model.state_dict())\n",
    "                saved = True\n",
    "                \n",
    "            if saved:\n",
    "                print(Fore.GREEN + f\"Training Loss(Accuracy): {train_loss:.2f}({train_acc:.2f}), Validation Loss(Accuracy): {valid_loss:.2f}({valid_acc:.2f})\")\n",
    "                saved = False\n",
    "            else:\n",
    "                print(Fore.RED + f\"Training Loss(Accuracy): {train_loss:.2f}({train_acc:.2f}), Validation Loss(Accuracy): {valid_loss:.2f}({valid_acc:.2f})\")\n",
    "\n",
    "            model.train()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(Fore.YELLOW + \"=\" * 74)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e70ff28-024e-4b1b-ae01-16fa6939ac9b",
   "metadata": {},
   "source": [
    "# Model Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989bdcd9-8f1c-4221-bdb6-b9b7bc2955b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model_loss, \"Best models/\", \"best_model_2D_loss.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbd327-9c7c-43c8-98e8-31bfd900138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"Best models/best_model_2D_loss.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06ea58-3c62-4760-adbe-70ba8ca362bf",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4209bf-c1c9-4a61-89e3-be09c54844fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_report(model, valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697e1da-84ab-4ecf-83f6-bcc6bed6aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_report(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac0d7d-6a61-4805-b077-54d17dcf285e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
