{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652af7e-f4c1-46f5-9983-e9f073df1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6811b-a6c9-4615-9ffc-1010c0f8098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have access to moduels\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.realpath('')) + '/Modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f07af-82db-4f43-b7ae-17f0e5ae8793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose, Resize\n",
    "\n",
    "from transformers import ViTConfig, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from dataloader.dataset import ADNI3Channels\n",
    "from dataloader.dataloader import ADNILoader\n",
    "\n",
    "from utils.report import sklearn_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524579bc-fa07-4fd3-8b03-7a6c7090d8cd",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146f265-19e4-4098-8596-08370ce8b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (384, 384)\n",
    "resize = Resize(size=image_size)\n",
    "\n",
    "train_transforms = Compose([resize])\n",
    "valid_transforms = Compose([resize])\n",
    "test_transforms = Compose([resize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d16e77-75f9-4675-a538-767aee133120",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ADNI3Channels(\"../Data/Training/\", transforms=train_transforms)\n",
    "valid_ds = ADNI3Channels(\"../Data/Validation/\", transforms=valid_transforms)\n",
    "test_ds = ADNI3Channels(\"../Data/Test/\", transforms=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053da8b9-7744-4552-9db5-c93ad3307c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "image, label = train_ds[idx]\n",
    "\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label:\", label.item())\n",
    "\n",
    "print(\"Number of training samples:\", len(train_ds))\n",
    "print(\"Number of validation samples:\", len(valid_ds))\n",
    "print(\"Number of test samples:\", len(test_ds), \"\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(6, 2), dpi=300)\n",
    "for i in range(3):\n",
    "    axes[i].imshow(image[i, :, :])\n",
    "    axes[i].axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75590ba-ad21-496b-9a08-f6992fd77369",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"CN\", 1: \"MCI\", 2: \"AD\"}\n",
    "label2id = {\"CN\": 0, \"MCI\": 1, \"AD\": 2}\n",
    "\n",
    "print(id2label[label.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9beb7-69d8-4fdc-84e0-fb3bc1bfb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 10\n",
    "valid_batch_size = 5\n",
    "test_batch_size = 5\n",
    "\n",
    "hparams = {'train_ds': train_ds,\n",
    "           'valid_ds': valid_ds,\n",
    "           'test_ds': test_ds,\n",
    "           'train_batch_size': train_batch_size,\n",
    "           'valid_batch_size': valid_batch_size,\n",
    "           'test_batch_size': test_batch_size,\n",
    "           'num_workers': 20,\n",
    "           'train_shuffle': False,\n",
    "           'valid_shuffle': False,\n",
    "           'test_shuffle': False,\n",
    "           'train_drop_last': False,\n",
    "           'valid_drop_last': False,\n",
    "           'test_drop_last': False,\n",
    "          }\n",
    "\n",
    "train_dataloader = ADNILoader(**hparams).train_dataloader()\n",
    "valid_dataloader= ADNILoader(**hparams).validation_dataloader()\n",
    "test_dataloader = ADNILoader(**hparams).test_dataloader()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch[0].shape)\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f30a4-a8e6-425b-837d-135bdd21c37f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f2a47-3338-43a0-b27f-7d369c471629",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_config = ViTConfig(image_size=image_size,\n",
    "                       patch_size=32,\n",
    "                       num_labels=3,\n",
    "                       output_attentions=True,\n",
    "                       output_hidden_states=True,\n",
    "                       hidden_dropout_prob=0.1,\n",
    "                       # attention_probs_dropout_prob=0.1,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c401b-ee88-4fc1-aa28-8a64c390e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_labels=3, return_last_hidden_state=False):\n",
    "        super(ViT, self).__init__()\n",
    "        self.return_last_hidden_state = return_last_hidden_state\n",
    "        self.vit = ViTForImageClassification(vit_config)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(x)\n",
    "        if self.return_last_hidden_state:\n",
    "            return outputs.logits, outputs.attentions, outputs.hidden_states\n",
    "        else:\n",
    "            return outputs.logits, outputs.attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca08dc-c80e-487a-98be-eb180b6a3cca",
   "metadata": {},
   "source": [
    "# Saving Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e6a47-59fb-43b4-8a2b-b8b282f63d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu') \n",
    "model = ViT(return_last_hidden_state=False).to(device)\n",
    "feature_extractor = ViTFeatureExtractor(size=image_size,\n",
    "                                        patch_size=32,\n",
    "                                        do_resize=False,\n",
    "                                        do_normalize=False)\n",
    "\n",
    "model.load_state_dict(torch.load(\"../ViT/Best models/ViT_loss.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24c08b-140e-4cc4-9812-2ae1fcf70a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (x, y) in enumerate(dataloader):\n",
    "            x = np.split(np.array(x), dataloader.batch_size)\n",
    "            for i in range(len(x)):\n",
    "                x[i] = np.squeeze(x[i])\n",
    "            x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n",
    "            x, y  = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            preds = logits.argmax(1)\n",
    "        \n",
    "            y_pred.append(preds.cpu().numpy())\n",
    "            y_true.append(y.cpu().numpy())\n",
    "\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred = predict(model, test_dataloader, device)\n",
    "sklearn_classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1ae5e-e8b4-4587-b196-4bb847006b33",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preparing Activation and Label Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e2099-b92b-47c7-98f9-4454e45953af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame()\n",
    "y_train_df = pd.DataFrame()\n",
    "\n",
    "x_test_df = pd.DataFrame()\n",
    "y_test_df = pd.DataFrame()\n",
    "\n",
    "model.return_last_hidden_state = True\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample, label in train_dataloader:\n",
    "        sample = np.split(np.array(sample), train_batch_size)\n",
    "        for i in range(len(sample)):\n",
    "            sample[i] = np.squeeze(sample[i])\n",
    "        sample = torch.tensor(np.stack(feature_extractor(sample)['pixel_values'], axis=0))\n",
    "        sample, label  = sample.to(device), label.to(device)\n",
    "        _, _, activation = model(sample)\n",
    "\n",
    "        act_df = pd.DataFrame(activation[12].reshape((train_batch_size, 145*768)).detach().numpy())\n",
    "        label_df = pd.DataFrame(label.detach().numpy())\n",
    "\n",
    "        x_train_df = pd.concat([x_train_df, act_df])\n",
    "        y_train_df = pd.concat([y_train_df, label_df])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample, label in test_dataloader:\n",
    "        sample = np.split(np.array(sample), test_batch_size)\n",
    "        for i in range(len(sample)):\n",
    "            sample[i] = np.squeeze(sample[i])\n",
    "        sample = torch.tensor(np.stack(feature_extractor(sample)['pixel_values'], axis=0))\n",
    "        sample, label  = sample.to(device), label.to(device)\n",
    "        _, _, activation = model(sample)\n",
    "\n",
    "        act_df = pd.DataFrame(activation[12].reshape((test_batch_size, 145*768)).detach().numpy())\n",
    "        label_df = pd.DataFrame(label.detach().numpy())\n",
    "\n",
    "        x_test_df = pd.concat([x_test_df, act_df])\n",
    "        y_test_df = pd.concat([y_test_df, label_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b5676-9156-4984-ac80-16c9bc6916dd",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cb6c1-08e8-44ad-bc11-3119a216afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df = x_train_df.reset_index(drop=True)\n",
    "y_train_df = y_train_df.rename(columns={0: \"target\"}).reset_index(drop=True)\n",
    "x_test_df = x_test_df.reset_index(drop=True)\n",
    "y_test_df = y_test_df.rename(columns={0: \"target\"}).reset_index(drop=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_std = scaler.fit_transform(x_train_df)\n",
    "x_test_std = scaler.fit_transform(x_test_df)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_train = pca.fit_transform(x_train_std)\n",
    "pca_test = pca.fit_transform(x_test_std)\n",
    "\n",
    "pca_train_df = pd.DataFrame(pca_train, columns = ['principal component 1', 'principal component 2'])\n",
    "pca_test_df = pd.DataFrame(pca_test, columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "final_train_df = pd.concat([pca_train_df, y_train_df], axis = 1)\n",
    "final_test_df = pd.concat([pca_test_df, y_test_df], axis = 1)\n",
    "\n",
    "final_df = pd.concat([final_train_df, final_test_df], axis = 0, keys=['train', 'test'])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda2d40-a57e-4854-bbb1-cad7d65a9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8), dpi=300)\n",
    "targets = [0, 1, 2]\n",
    "colors = ['r', 'g', 'b']\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    sample_df = final_df[final_df['target'] == targets[i]]\n",
    "    \n",
    "    ax.scatter(sample_df.loc['train', 'principal component 1'],\n",
    "               sample_df.loc['train', 'principal component 2'],\n",
    "               s=150,\n",
    "               alpha=0.3,\n",
    "               c=colors[i],\n",
    "               marker='o',\n",
    "               label=f'{id2label[targets[i]]} (Train)'\n",
    "              )\n",
    "    \n",
    "    ax.scatter(sample_df.loc['test', 'principal component 1'],\n",
    "               sample_df.loc['test', 'principal component 2'],\n",
    "               s=150,\n",
    "               alpha=0.3,\n",
    "               c=colors[i],\n",
    "               marker='*',\n",
    "               label=f'{id2label[targets[i]]} (Test)'\n",
    "              )\n",
    "    \n",
    "ax.legend();\n",
    "ax.set_xlabel('Principle Component 1')\n",
    "ax.set_ylabel('Principle Component 2');\n",
    "# plt.savefig('PCA_ViT.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f63601-a150-4d37-86bb-7100031faab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
