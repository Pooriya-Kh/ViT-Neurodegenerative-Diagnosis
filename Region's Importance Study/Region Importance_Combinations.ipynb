{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c3fcc-5ae2-4a23-a104-9606fb86214e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5cbf8-9d6d-4f73-805c-0c351ce06900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have access to moduels\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.realpath('')) + '/Modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84422c53-a127-4767-8ea5-9c8282b6fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from torchvision.transforms import Resize, Compose, GaussianBlur, RandomRotation, RandomChoice, RandomApply, RandomAffine, ColorJitter, RandomHorizontalFlip, RandomVerticalFlip\n",
    "from dataloader.transforms import GaussianNoise\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from colorama import Fore\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from transformers import ViTConfig, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from itertools import combinations\n",
    "from ast import literal_eval\n",
    "\n",
    "from dataloader.dataset import ADNI3Channels\n",
    "from dataloader.dataloader import ADNILoader\n",
    "from atlas.atlas import ReadersAtlas3Channels, AAL3Channels\n",
    "\n",
    "from utils.utils import count_parameters, save_model\n",
    "from utils.report import sklearn_classification_report, custom_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b159d54-7226-401c-816f-f83ee5783bff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset and Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ce338-184d-4378-a7da-d22ff6723aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (384, 384)\n",
    "resize = Resize(size=image_size)\n",
    "\n",
    "gaussian_blur = GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2))\n",
    "gaussian_noise = GaussianNoise(mean=0, std=0.05)\n",
    "random_rotation = RandomRotation(degrees=2)\n",
    "random_translate = RandomAffine(degrees=0, translate=(0.01, 0.01))\n",
    "color_jitter_brightness = ColorJitter(brightness=0.1)\n",
    "color_jitter_contrast = ColorJitter(contrast=0.1)\n",
    "color_jitter_saturation = ColorJitter(saturation=0.1)\n",
    "random_vertical_flip = RandomVerticalFlip(0.5)\n",
    "random_horizontal_flip = RandomHorizontalFlip(0.5)\n",
    "\n",
    "random_choice = RandomChoice([gaussian_blur,\n",
    "                              gaussian_noise,\n",
    "                              color_jitter_brightness,\n",
    "                              color_jitter_contrast,\n",
    "                              color_jitter_saturation,\n",
    "                              # random_rotation,\n",
    "                              # random_translate,\n",
    "                              # random_vertical_flip,\n",
    "                              # random_horizontal_flip\n",
    "                             ])\n",
    "random_transforms = RandomApply([random_choice], p=0.7)\n",
    "\n",
    "train_transforms = Compose([])\n",
    "valid_transforms = Compose([])\n",
    "test_transforms = Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b2527-bf3f-4b5e-ac60-132b26c34f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ADNI3Channels(\"../Data/Training/\", transforms=train_transforms, rotate=True)\n",
    "valid_ds = ADNI3Channels(\"../Data/Validation/\", transforms=valid_transforms, rotate=True)\n",
    "test_ds = ADNI3Channels(\"../Data/Test/\", transforms=test_transforms, rotate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4e16a-ec1c-4e73-ba2f-6cc086513e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "image, label = train_ds[idx]\n",
    "\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label:\", label.item())\n",
    "\n",
    "print(\"Number of training samples:\", len(train_ds))\n",
    "print(\"Number of validation samples:\", len(valid_ds))\n",
    "print(\"Number of test samples:\", len(test_ds), \"\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(6, 2), dpi=300)\n",
    "for i in range(3):\n",
    "    axes[i].imshow(image[i, :, :])\n",
    "    axes[i].axis(\"off\");\n",
    "    # print(image[i, :, :].min(), image[i, :, :].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"CN\", 1: \"MCI\", 2: \"AD\"}\n",
    "label2id = {\"CN\": 0, \"MCI\": 1, \"AD\": 2}\n",
    "\n",
    "print(id2label[label.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f342a0-b447-4fb1-9f2d-f31478574b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch_size = 10\n",
    "valid_batch_size = 5\n",
    "test_batch_size = 5\n",
    "\n",
    "hparams = {'train_ds': train_ds,\n",
    "           'valid_ds': valid_ds,\n",
    "           'test_ds': test_ds,\n",
    "           'train_batch_size': train_batch_size,\n",
    "           'valid_batch_size': valid_batch_size,\n",
    "           'test_batch_size': test_batch_size,\n",
    "           'num_workers': 20,\n",
    "           'train_shuffle': True,\n",
    "           'valid_shuffle': False,\n",
    "           'test_shuffle': False,\n",
    "           'train_drop_last': False,\n",
    "           'valid_drop_last': False,\n",
    "           'test_drop_last': False,\n",
    "          }\n",
    "\n",
    "train_dataloader = ADNILoader(**hparams).train_dataloader()\n",
    "valid_dataloader= ADNILoader(**hparams).validation_dataloader()\n",
    "test_dataloader = ADNILoader(**hparams).test_dataloader()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch[0].shape)\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2e0d5-3663-4c5d-8a33-c2eaf19068ef",
   "metadata": {},
   "source": [
    "# Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4efe9-782f-4fb4-8fa4-bcd3a23870ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_data, atlas_labels = ReadersAtlas3Channels(aal_dir='../Data/AAL/Resized_AAL.nii',\n",
    "                                                 labels_dir='../Data/AAL/ROI_MNI_V4.txt',\n",
    "                                                 rotate=True).get_data()\n",
    "\n",
    "print(atlas_data.shape, '\\n')\n",
    "print(atlas_labels, '\\n')\n",
    "        \n",
    "fig, axes = plt.subplots(ncols=3, figsize=(6, 2), dpi=300)\n",
    "for i in range(3):\n",
    "    axes[i].imshow(atlas_data[i, :, :])\n",
    "    axes[i].axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591ff39-1635-4da8-a1b9-2bd844ca5229",
   "metadata": {},
   "source": [
    "# Regions Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce5b3a-51f8-48a9-b52b-97a0e024fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_comb = combinations(list(atlas_labels), 2)\n",
    "region_comb = [r for r in region_comb]\n",
    "len(region_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed18ae1-e86b-4e18-a833-fd2abe0dfdcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274eefc-a1d1-482a-b8b9-d63e89b4cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = True\n",
    "vit_config = ViTConfig(image_size=image_size,\n",
    "                       patch_size=32,\n",
    "                       num_labels=3,\n",
    "                       output_attentions=True,\n",
    "                       hidden_dropout_prob=0.1,\n",
    "                       # attention_probs_dropout_prob=0.1,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cab3b-b09d-4d5d-b77a-0fe10cff670f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_labels=3, pretrained=False):\n",
    "        super(ViT, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        \n",
    "        if self.pretrained:\n",
    "            self.vit = ViTForImageClassification.from_pretrained('google/vit-base-patch32-384',\n",
    "                                                                 output_attentions=True,\n",
    "                                                                 num_labels=num_labels,\n",
    "                                                                 hidden_dropout_prob=0.1,\n",
    "                                                                 # attention_probs_dropout_prob=0.1,\n",
    "                                                                 ignore_mismatched_sizes=True\n",
    "                                                                )\n",
    "        else:\n",
    "            self.vit = ViTForImageClassification(vit_config)\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(x)\n",
    "        return outputs.logits, outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6da4e-8b63-4387-9785-b2d6378d8a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting GPU\n",
    "GPU = {0: torch.device('cuda:0'),\n",
    "       1: torch.device('cuda:1'),\n",
    "       2: torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "      }\n",
    "\n",
    "## Single-GPU trining\n",
    "device = GPU[1]\n",
    "model = ViT(num_labels=3, pretrained=pretrained).to(device)\n",
    "\n",
    "## Multi-GPU training\n",
    "# device = GPU[2]\n",
    "# model = ViT(num_labels=3, pretrained=pretrained)\n",
    "# model= nn.DataParallel(model)\n",
    "# model.to(device);\n",
    "\n",
    "if pretrained:\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch32-384',\n",
    "                                                            do_resize=False,\n",
    "                                                            do_normalize=False)\n",
    "else:\n",
    "    feature_extractor = ViTFeatureExtractor(do_resize=False,\n",
    "                                            size=image_size,\n",
    "                                            do_normalize=False)\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.15)\n",
    "\n",
    "class_0_freq = 140\n",
    "class_1_freq = 160\n",
    "class_2_freq = 160\n",
    "weight = torch.tensor([1/class_0_freq, 1/class_1_freq, 1/class_2_freq]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight)\n",
    "\n",
    "accuracy = Accuracy()\n",
    "writer = SummaryWriter()\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685fb91-30c2-4960-ab63-f99b522bc50e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "train_loss_history = {comb_i: [] for comb_i in range(len(region_comb))}\n",
    "train_acc_history = {comb_i: [] for comb_i in range(len(region_comb))}\n",
    "\n",
    "for comb_i in range(len(region_comb)):\n",
    "    print(Fore.WHITE + f'Region: {comb_i} {region_comb[comb_i]}')\n",
    "    \n",
    "    train_accs = []\n",
    "    train_losses = []\n",
    "    best_loss = 100\n",
    "    best_acc = 0\n",
    "    saved = False\n",
    "    \n",
    "    model = ViT(num_labels=3, pretrained=pretrained).to(device)\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch32-384',\n",
    "                                                            do_resize=False,\n",
    "                                                            do_normalize=False)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "    class_0_freq = 140\n",
    "    class_1_freq = 160\n",
    "    class_2_freq = 160\n",
    "    weight = torch.tensor([1/class_0_freq, 1/class_1_freq, 1/class_2_freq]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    accuracy = Accuracy()\n",
    "    writer = SummaryWriter()\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.999)\n",
    "    \n",
    "    mask1 = torch.where(atlas_data==atlas_labels[region_comb[comb_i][0]], 1, 0)\n",
    "    mask2 = torch.where(atlas_data==atlas_labels[region_comb[comb_i][1]], 1, 0)\n",
    "    mask = mask1 + mask2\n",
    "    atlas_subregion = atlas_data * mask\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for step, (x, y) in enumerate(train_dataloader):\n",
    "            \n",
    "            x *= atlas_subregion\n",
    "            x = resize(x)\n",
    "            \n",
    "            x = np.split(np.array(x), train_batch_size)\n",
    "            for i in range(len(x)):\n",
    "                x[i] = np.squeeze(x[i])\n",
    "            x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n",
    "            x, y  = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            criterion.weight = weight\n",
    "            loss = criterion(logits, y)\n",
    "            preds = logits.argmax(1)\n",
    "            acc = accuracy(y.cpu(), preds.cpu())\n",
    "            optimizer.zero_grad()           \n",
    "            loss.backward()                 \n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            train_accs.append(acc.item())\n",
    "\n",
    "        train_loss = sum(train_losses)/len(train_losses)\n",
    "        train_acc = sum(train_accs)/len(train_accs)\n",
    "        \n",
    "        train_loss_history[comb_i].append(train_loss)\n",
    "        train_acc_history[comb_i].append(train_acc)\n",
    "        \n",
    "        writer.add_scalar('train_loss', train_loss, epoch * len(train_dataloader) + step)\n",
    "        writer.add_scalar('train_acc', train_acc, epoch * len(train_dataloader) + step)\n",
    "        \n",
    "        train_losses.clear()\n",
    "        train_accs.clear()\n",
    "        \n",
    "        \n",
    "\n",
    "        if best_loss > train_loss:\n",
    "            best_loss = train_loss\n",
    "            # best_model_loss = deepcopy(model.state_dict())\n",
    "            # torch.save(best_model_loss, f\"best_model_loss_comb_{comb_i}.pt\")\n",
    "            saved = True\n",
    "\n",
    "        if best_acc < train_acc:\n",
    "            best_acc = train_acc\n",
    "            # best_model_acc = deepcopy(model.state_dict())\n",
    "            # torch.save(best_model_acc, f\"best_model_acc_comb_{comb_i}.pt\")\n",
    "            saved = True\n",
    "\n",
    "        if saved:\n",
    "            print(Fore.GREEN + f\"Epoch: {(epoch+1):02}/{epochs} | Training Loss(Accuracy): {train_loss:.2f}({train_acc:.2f})\")\n",
    "            saved = False\n",
    "        else:\n",
    "            print(Fore.RED + f\"Epoch: {(epoch+1):02}/{epochs} | Training Loss(Accuracy): {train_loss:.2f}({train_acc:.2f})\")\n",
    "        \n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "    with open(\"history.txt\", 'w') as f:\n",
    "        f.write('train_loss_history = ' + str(train_loss_history) + '\\n\\n')\n",
    "        f.write('train_acc_history = ' + str(train_acc_history))\n",
    "    \n",
    "    print(Fore.YELLOW + \"=\" * 74)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559633bf-b6c1-4f2c-847b-da4042ffb883",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regions' Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7776d7-31cf-4ae3-b873-02bce471491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the history file and converting strings to dictionaries\n",
    "f = open('history_comb.txt', 'r')\n",
    "txt = f.read()\n",
    "txt = txt.split('\\n')\n",
    "f.close()\n",
    "\n",
    "train_loss_history_str = txt[0]\n",
    "train_acc_history_str = txt[-1]\n",
    "\n",
    "train_loss_history_str = train_loss_history_str[train_loss_history_str.find('{'): train_loss_history_str.find('}') + 1]\n",
    "train_acc_history_str = train_acc_history_str[train_acc_history_str.find('{'): train_acc_history_str.find('}') + 1]\n",
    "\n",
    "\n",
    "train_loss_history = literal_eval(train_loss_history_str)\n",
    "train_acc_history = literal_eval(train_acc_history_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3281cc2-7c5a-4549-9bce-32a5f8d7a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the lowest loss and highest accuracy for each region\n",
    "for key, value in train_loss_history.items():\n",
    "    train_loss_history[key] = min(value)\n",
    "    \n",
    "for key, value in train_acc_history.items():\n",
    "    train_acc_history[key] = max(value)\n",
    "\n",
    "# Sorting regions based on loss and accuracy\n",
    "train_loss_history = dict(sorted(train_loss_history.items(), key=lambda x:x[1], reverse=False))\n",
    "train_acc_history = dict(sorted(train_acc_history.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8ab2e-0d51-4fab-8e05-f1200eefbd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10), dpi=300)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "l = []\n",
    "\n",
    "for i, (key, value) in enumerate(train_loss_history.items()):\n",
    "    x.append(str(i))\n",
    "    y.append(value)\n",
    "    l.append(f'{i}: {region_comb[key]}')\n",
    "    \n",
    "my_cmap = plt.cm.get_cmap('viridis')\n",
    "colors = my_cmap(np.linspace(0, 1, 28))\n",
    "\n",
    "bar = ax.bar(x=x,\n",
    "             height=y,\n",
    "             width=0.6,\n",
    "             color=colors,\n",
    "             edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=20)\n",
    "ax.set_ylabel('Training Loss', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(handles=bar, labels=l, fontsize=15, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc771c-4146-4a62-827e-839da4d0ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10), dpi=300)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "l = []\n",
    "\n",
    "for i, (key, value) in enumerate(train_acc_history.items()):\n",
    "    x.append(str(i))\n",
    "    y.append(value)\n",
    "    l.append(f'{i}: {region_comb[key]}')\n",
    "\n",
    "my_cmap = plt.cm.get_cmap('viridis')\n",
    "colors = my_cmap(np.linspace(0, 1, 28))\n",
    "\n",
    "bar = ax.bar(x=x,\n",
    "             height=y,\n",
    "             width=0.6,\n",
    "             color=colors,\n",
    "             edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=20)\n",
    "ax.set_ylabel('Training Accuracy (Region Importance)', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(handles=bar, labels=l, fontsize=15, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc9b8f-29c1-4e7b-9bcb-09c7cbfd4004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
